# BERT model configuration for semantic similarity
bert_model:
  model_id: "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
  threshold: 0.75
  use_cpu: true

default_model: "mistral-small3.1"

# Categories and tasks for model routing
categories:
  - name: "STEM"
    description: "Science, Technology, Engineering, and Mathematics topics"
    model: "phi4:latest"
    tasks:
      - name: "Mathematics"
        description: "Mathematical problems, calculations, and theorems"
        typical_prompt: "You are a math professional. Explain math concepts clearly and show step-by-step solutions to problems."
      - name: "Physics"
        description: "Physics principles, problems, and phenomena explanations"
        typical_prompt: "You are a physics professional. Explain physics concepts in simple terms with examples that are easy to understand."
      - name: "Computer Science"
        description: "Computer algorithms, data structures, and computational problems"
        typical_prompt: "You are a computer science professional. Explain coding concepts and algorithms in simple terms. Show examples when needed."

  - name: "Creative Tasks"
    description: "Writing, art, music, and creative expression"
    model: "gemma3:27b"
    tasks:
      - name: "Story Writing"
        description: "Generate creative narratives and fictional content"
        typical_prompt: "You are a story writer. Create interesting stories with good characters and settings."
      - name: "Brainstorming"
        description: "Generate creative ideas for projects, marketing, or problem solving"
        typical_prompt: "You are an idea generator. Come up with creative ideas for different projects and problems."

# Semantic cache configuration
semantic_cache:
  enabled: true
  similarity_threshold: 0.80 
  max_entries: 1000
  ttl_seconds: 3600